{
  "patch": "diff --git a/scrapy/downloadermiddlewares/retry.py b/scrapy/downloadermiddlewares/retry.py\nindex 081642a4b..9547ad061 100644\n--- a/scrapy/downloadermiddlewares/retry.py\n+++ b/scrapy/downloadermiddlewares/retry.py\n@@ -124,19 +124,7 @@ def get_retry_request(\n class RetryMiddleware:\n     # IOError is raised by the HttpCompression middleware when trying to\n     # decompress an empty response\n-    EXCEPTIONS_TO_RETRY = (\n-        defer.TimeoutError,\n-        TimeoutError,\n-        DNSLookupError,\n-        ConnectionRefusedError,\n-        ConnectionDone,\n-        ConnectError,\n-        ConnectionLost,\n-        TCPTimedOutError,\n-        ResponseFailed,\n-        IOError,\n-        TunnelError,\n-    )\n+    # Remove EXCEPTIONS_TO_RETRY as it's now configurable\n \n     def __init__(self, settings):\n         if not settings.getbool(\"RETRY_ENABLED\"):\n@@ -146,6 +134,8 @@ class RetryMiddleware:\n             int(x) for x in settings.getlist(\"RETRY_HTTP_CODES\")\n         )\n         self.priority_adjust = settings.getint(\"RETRY_PRIORITY_ADJUST\")\n+        self.retry_exceptions = settings.getlist(\"RETRY_EXCEPTIONS\", default=self.EXCEPTIONS_TO_RETRY)\n+        self.retry_exceptions = tuple(exception if isinstance(exception, type) else getattr(__builtins__, exception) for exception in self.retry_exceptions)\n \n     @classmethod\n     def from_crawler(cls, crawler):\n@@ -160,7 +150,7 @@ class RetryMiddleware:\n         return response\n \n     def process_exception(self, request, exception, spider):\n-        if isinstance(exception, self.EXCEPTIONS_TO_RETRY) and not request.meta.get(\n+        if isinstance(exception, self.retry_exceptions) and not request.meta.get(\n             \"dont_retry\", False\n         ):\n             return self._retry(request, exception, spider)\n"
}