{
  "patch": "To address the issue of handling non-UTF-8 encoded Content-Type headers in the Scrapy framework, we need to focus on the `from_content_type` method within the `ResponseTypes` class. This method is responsible for determining the most appropriate response class based on the HTTP Content-Type header.\n\nThe problem arises because the `to_unicode` function is used to convert the `content_type` to Unicode, which assumes UTF-8 encoding by default. However, when the Content-Type header is not encoded in UTF-8 (e.g., when it's encoded in `windows-1251`), this conversion fails, leading to a `UnicodeDecodeError`.\n\nTo fix this issue, we need to modify the `from_content_type` method to handle the conversion of `content_type` to Unicode in a way that can accommodate non-UTF-8 encodings. Given that the `content_type` is typically a short string and using `latin-1` (also known as ISO-8859-1) for such conversions is a common approach to avoid decoding errors, we can adjust the method as follows:\n\n```\n<file>scrapy/responsetypes.py</file>\n<original>\n54         mimetype = to_unicode(content_type).split(\";\")[0].strip().lower()\n</original>\n<patched>\n54         mimetype = to_unicode(content_type, encoding=\"latin-1\").split(\";\")[0].strip().lower()\n</patched>\n```\n\nThis change ensures that the `content_type` is converted to Unicode using `latin-1` encoding, which will not throw a decoding error for bytes that are not valid UTF-8. This approach allows the `from_content_type` method to handle Content-Type headers with non-UTF-8 encodings, such as `windows-1251`, thereby resolving the issue at hand. \n\nNo additional modifications are necessary beyond this change to address the specific problem described. The rest of the provided code context and potential modification locations do not require alterations for this particular fix."
}