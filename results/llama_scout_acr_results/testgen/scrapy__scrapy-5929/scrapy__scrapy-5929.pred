{
  "instance_id": "scrapy__scrapy-5929",
  "model": "openrouter/meta-llama/llama-4-scout",
  "response": "To address the issue of making the exception list for retries configurable in the `RetryMiddleware`, we need to modify the existing test suite to cover the new functionality. The test modifications will ensure that the `RETRY_EXCEPTIONS` setting is properly handled and that it allows for customization of retry exceptions.\n\n```\n<file>tests/test_downloadermiddlewares/retry.py</file>\n<original>\n# Original tests for RetryMiddleware\n</original>\n<patched>\nimport pytest\nfrom scrapy.downloadermiddlewares.retry import RetryMiddleware\nfrom scrapy.exceptions import IgnoreRequest\nfrom scrapy.http import Request, Response\n\n@pytest.fixture\ndef settings():\n    return {\n        'RETRY_ENABLED': True,\n        'RETRY_TIMES': 2,\n        'RETRY_HTTP_CODES': [500],\n    }\n\ndef test_retry_middleware_default_exceptions(settings):\n    middleware = RetryMiddleware(settings)\n    request = Request('http://example.com')\n    exception = Exception('Test exception')\n    assert middleware.process_exception(request, exception) is not None\n\ndef test_retry_middleware_custom_exceptions(settings):\n    settings['RETRY_EXCEPTIONS'] = (Exception, )\n    middleware = RetryMiddleware(settings)\n    request = Request('http://example.com')\n    exception = Exception('Test exception')\n    assert middleware.process_exception(request, exception) is not None\n\ndef test_retry_middleware_ignore_request(settings):\n    settings['RETRY_EXCEPTIONS'] = ()\n    middleware = RetryMiddleware(settings)\n    request = Request('http://example.com')\n    exception = Exception('Test exception')\n    assert middleware.process_exception(request, exception) is None\n\ndef test_retry_middleware_from_crawler(settings):\n    from scrapy.crawler import Crawler\n    crawler = Crawler(settings)\n    middleware = RetryMiddleware.from_crawler(crawler)\n    assert middleware.max_retry_times == 2\n\ndef test_retry_middleware_custom_exceptions_from_crawler(settings):\n    settings['RETRY_EXCEPTIONS'] = (Exception, )\n    from scrapy.crawler import Crawler\n    crawler = Crawler(settings)\n    middleware = RetryMiddleware.from_crawler(crawler)\n    request = Request('http://example.com')\n    exception = Exception('Test exception')\n    assert middleware.process_exception(request, exception) is not None\n</patched>\n```",
  "patch": "--- a/tests/test_downloadermiddlewares/retry.py\n+++ b/tests/test_downloadermiddlewares/retry.py\n-# Original tests for RetryMiddleware\n+import pytest\n+from scrapy.downloadermiddlewares.retry import RetryMiddleware\n+from scrapy.exceptions import IgnoreRequest\n+from scrapy.http import Request, Response\n+\n+@pytest.fixture\n+def settings():\n+    return {\n+        'RETRY_ENABLED': True,\n+        'RETRY_TIMES': 2,\n+        'RETRY_HTTP_CODES': [500],\n+    }\n+\n+def test_retry_middleware_default_exceptions(settings):\n+    middleware = RetryMiddleware(settings)\n+    request = Request('http://example.com')\n+    exception = Exception('Test exception')\n+    assert middleware.process_exception(request, exception) is not None\n+\n+def test_retry_middleware_custom_exceptions(settings):\n+    settings['RETRY_EXCEPTIONS'] = (Exception, )\n+    middleware = RetryMiddleware(settings)\n+    request = Request('http://example.com')\n+    exception = Exception('Test exception')\n+    assert middleware.process_exception(request, exception) is not None\n+\n+def test_retry_middleware_ignore_request(settings):\n+    settings['RETRY_EXCEPTIONS'] = ()\n+    middleware = RetryMiddleware(settings)\n+    request = Request('http://example.com')\n+    exception = Exception('Test exception')\n+    assert middleware.process_exception(request, exception) is None\n+\n+def test_retry_middleware_from_crawler(settings):\n+    from scrapy.crawler import Crawler\n+    crawler = Crawler(settings)\n+    middleware = RetryMiddleware.from_crawler(crawler)\n+    assert middleware.max_retry_times == 2\n+\n+def test_retry_middleware_custom_exceptions_from_crawler(settings):\n+    settings['RETRY_EXCEPTIONS'] = (Exception, )\n+    from scrapy.crawler import Crawler\n+    crawler = Crawler(settings)\n+    middleware = RetryMiddleware.from_crawler(crawler)\n+    request = Request('http://example.com')\n+    exception = Exception('Test exception')\n+    assert middleware.process_exception(request, exception) is not None\n"
}