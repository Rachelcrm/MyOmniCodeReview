{
  "patch": "diff --git a/scrapy/spidermiddlewares/offsite.py b/scrapy/spidermiddlewares/offsite.py\nindex d3ed64ef5..8744fca72 100644\n--- a/scrapy/spidermiddlewares/offsite.py\n+++ b/scrapy/spidermiddlewares/offsite.py\n@@ -44,8 +44,27 @@ class OffsiteMiddleware:\n         assert crawler.stats\n         o = cls(crawler.stats)\n         crawler.signals.connect(o.spider_opened, signal=signals.spider_opened)\n+        crawler.signals.connect(o.request_scheduled, signal=signals.request_scheduled)\n         return o\n \n+    def request_scheduled(self, request: Request, spider: Spider) -> None:\n+        self.process_request(request, spider)\n+\n+    def process_request(self, request: Request, spider: Spider) -> None:\n+        if request.dont_filter or self.should_follow(request, spider):\n+            return\n+        domain = urlparse_cached(request).hostname\n+        if domain and domain not in self.domains_seen:\n+            self.domains_seen.add(domain)\n+            logger.debug(\n+                \"Filtered offsite request to %(domain)r: %(request)s\",\n+                {\"domain\": domain, \"request\": request},\n+                extra={\"spider\": spider},\n+            )\n+            self.stats.inc_value(\"offsite/domains\", spider=spider)\n+        self.stats.inc_value(\"offsite/filtered\", spider=spider)\n+        raise IgnoreRequest\n+\n     def process_spider_output(\n         self, response: Response, result: Iterable[Any], spider: Spider\n     ) -> Iterable[Any]:\n"
}