--- a/tests/delete_regress/test_fast_delete_optimization.py
+++ b/tests/delete_regress/test_fast_delete_optimization.py
-# Empty if creating new file
+import pytest
+from django.db import models, connection
+from django.test import TestCase, TransactionTestCase
+from django.test.utils import override_settings
+from django.db.models.deletion import Collector
+from unittest.mock import patch, MagicMock
+
+
+class Person(models.Model):
+    name = models.CharField(max_length=100)
+    friends = models.ManyToManyField('self', symmetrical=False)
+    
+    class Meta:
+        app_label = 'delete_regress'
+
+
+class User(models.Model):
+    username = models.CharField(max_length=100)
+    
+    class Meta:
+        app_label = 'delete_regress'
+
+
+class Entry(models.Model):
+    title = models.CharField(max_length=100)
+    created_by = models.ForeignKey(User, on_delete=models.CASCADE, related_name='created_entries')
+    updated_by = models.ForeignKey(User, on_delete=models.CASCADE, related_name='updated_entries')
+    
+    class Meta:
+        app_label = 'delete_regress'
+
+
+class FastDeleteOptimizationTest(TransactionTestCase):
+    """Test that fast delete queries are combined when targeting the same table."""
+    
+    def setUp(self):
+        # Create test data
+        self.user1 = User.objects.create(username='user1')
+        self.user2 = User.objects.create(username='user2')
+        
+        # Create entries with multiple foreign keys to the same user
+        self.entry1 = Entry.objects.create(
+            title='Entry 1',
+            created_by=self.user1,
+            updated_by=self.user1
+        )
+        self.entry2 = Entry.objects.create(
+            title='Entry 2', 
+            created_by=self.user2,
+            updated_by=self.user1
+        )
+        
+        # Create person with self-referential many-to-many
+        self.person1 = Person.objects.create(name='Person 1')
+        self.person2 = Person.objects.create(name='Person 2')
+        self.person1.friends.add(self.person2)
+        self.person2.friends.add(self.person1)
+    
+    def test_user_delete_generates_separate_queries_before_fix(self):
+        """Test that deleting a user currently generates separate DELETE queries for each FK relationship."""
+        # This test demonstrates the current behavior (bug) - multiple queries for same table
+        with patch.object(connection, 'execute') as mock_execute:
+            # Mock the execute method to track SQL queries
+            mock_execute.return_value = None
+            
+            # Delete user1 which should trigger cascade deletes
+            collector = Collector(using='default')
+            collector.collect([self.user1])
+            
+            # Count how many fast_deletes target the Entry model
+            entry_fast_deletes = [qs for qs in collector.fast_deletes if hasattr(qs, 'model') and qs.model == Entry]
+            
+            # Before optimization, we expect 2 separate QuerySets for Entry model
+            # (one for created_by FK, one for updated_by FK)
+            self.assertGreaterEqual(len(entry_fast_deletes), 2, 
+                                  "Should have separate QuerySets for each FK relationship to same model")
+    
+    def test_person_delete_generates_separate_queries_before_fix(self):
+        """Test that deleting a person generates separate DELETE queries for M2M relationships."""
+        with patch.object(connection, 'execute') as mock_execute:
+            mock_execute.return_value = None
+            
+            collector = Collector(using='default')
+            collector.collect([self.person1])
+            
+            # Check for multiple fast_deletes targeting the same through table
+            through_model = Person.friends.through
+            through_fast_deletes = [qs for qs in collector.fast_deletes 
+                                  if hasattr(qs, 'model') and qs.model == through_model]
+            
+            # Before optimization, we expect separate QuerySets for from_person and to_person
+            self.assertGreaterEqual(len(through_fast_deletes), 2,
+                                  "Should have separate QuerySets for M2M from/to relationships")
+    
+    def test_fast_delete_query_combination_after_fix(self):
+        """Test that after optimization, queries targeting same table are combined."""
+        # This test will pass after the fix is implemented
+        collector = Collector(using='default')
+        collector.collect([self.user1])
+        
+        # Group fast_deletes by model to simulate the optimization
+        fast_deletes_by_model = {}
+        for qs in collector.fast_deletes:
+            if hasattr(qs, 'model'):
+                model = qs.model
+                if model not in fast_deletes_by_model:
+                    fast_deletes_by_model[model] = []
+                fast_deletes_by_model[model].append(qs)
+        
+        # After optimization, each model should ideally have only one combined query
+        for model, querysets in fast_deletes_by_model.items():
+            if len(querysets) > 1:
+                # This indicates the optimization opportunity exists
+                self.assertTrue(True, f"Model {model} has {len(querysets)} separate fast delete queries that could be combined")
+    
+    def test_combined_delete_preserves_deletion_count(self):
+        """Test that combining queries preserves accurate deletion counts."""
+        # Create additional entries to ensure we have multiple objects to delete
+        Entry.objects.create(title='Entry 3', created_by=self.user1, updated_by=self.user2)
+        Entry.objects.create(title='Entry 4', created_by=self.user2, updated_by=self.user1)
+        
+        # Count entries before deletion
+        initial_entry_count = Entry.objects.count()
+        entries_created_by_user1 = Entry.objects.filter(created_by=self.user1).count()
+        entries_updated_by_user1 = Entry.objects.filter(updated_by=self.user1).count()
+        
+        # Expected total deletions (accounting for overlap)
+        expected_deletions = Entry.objects.filter(
+            models.Q(created_by=self.user1) | models.Q(updated_by=self.user1)
+        ).count()
+        
+        # Perform deletion
+        deleted_count, deleted_details = self.user1.delete()
+        
+        # Verify correct number of entries were deleted
+        remaining_entries = Entry.objects.count()
+        actual_deletions = initial_entry_count - remaining_entries
+        
+        self.assertEqual(actual_deletions, expected_deletions,
+                        "Combined delete should delete correct number of entries")
+        
+        # Verify deletion count is reported correctly
+        self.assertIn('delete_regress.Entry', deleted_details)
+        self.assertEqual(deleted_details['delete_regress.Entry'], expected_deletions)
+    
+    def test_combined_delete_with_no_overlap(self):
+        """Test combining queries when there's no overlap between conditions."""
+        # Create a user that only appears in created_by
+        user3 = User.objects.create(username='user3')
+        Entry.objects.create(title='Entry by user3', created_by=user3, updated_by=self.user2)
+        
+        # Create a user that only appears in updated_by  
+        user4 = User.objects.create(username='user4')
+        Entry.objects.create(title='Entry updated by user4', created_by=self.user2, updated_by=user4)
+        
+        initial_count = Entry.objects.count()
+        
+        # Delete both users
+        User.objects.filter(id__in=[user3.id, user4.id]).delete()
+        
+        # Should have deleted 2 entries (one for each user)
+        final_count = Entry.objects.count()
+        self.assertEqual(initial_count - final_count, 2)
+    
+    def test_combined_delete_with_complete_overlap(self):
+        """Test combining queries when conditions completely overlap."""
+        # Create entries where user1 is both creator and updater
+        Entry.objects.create(title='Self-created 1', created_by=self.user1, updated_by=self.user1)
+        Entry.objects.create(title='Self-created 2', created_by=self.user1, updated_by=self.user1)
+        
+        entries_before = Entry.objects.filter(
+            models.Q(created_by=self.user1) | models.Q(updated_by=self.user1)
+        ).count()
+        
+        # Delete user1
+        self.user1.delete()
+        
+        # All entries should be deleted (no double-counting)
+        entries_after = Entry.objects.filter(
+            models.Q(created_by=self.user1) | models.Q(updated_by=self.user1)
+        ).count()
+        
+        self.assertEqual(entries_after, 0, "All related entries should be deleted")
+    
+    def test_m2m_delete_combination(self):
+        """Test that M2M delete queries can be combined."""
+        # Add more friendship relationships
+        person3 = Person.objects.create(name='Person 3')
+        self.person1.friends.add(person3)
+        person3.friends.add(self.person1)
+        
+        through_model = Person.friends.through
+        initial_relationships = through_model.objects.filter(
+            models.Q(from_person=self.person1) | models.Q(to_person=self.person1)
+        ).count()
+        
+        # Delete person1
+        self.person1.delete()
+        
+        # All relationships involving person1 should be deleted
+        remaining_relationships = through_model.objects.filter(
+            models.Q(from_person=self.person1) | models.Q(to_person=self.person1)
+        ).count()
+        
+        self.assertEqual(remaining_relationships, 0, 
+                        "All M2M relationships should be deleted")
+    
+    def test_mixed_model_fast_deletes_not_combined(self):
+        """Test that fast deletes for different models are not incorrectly combined."""
+        collector = Collector(using='default')
+        collector.collect([self.user1, self.person1])
+        
+        # Group by model
+        models_in_fast_deletes = set()
+        for qs in collector.fast_deletes:
+            if hasattr(qs, 'model'):
+                models_in_fast_deletes.add(qs.model)
+        
+        # Should have fast deletes for multiple different models
+        self.assertGreater(len(models_in_fast_deletes), 1,
+                          "Should have fast deletes for multiple models")
+    
+    def test_collector_fast_deletes_structure(self):
+        """Test the structure of fast_deletes to understand current behavior."""
+        collector = Collector(using='default')
+        collector.collect([self.user1])
+        
+        # Analyze the fast_deletes structure
+        fast_delete_info = []
+        for i, qs in enumerate(collector.fast_deletes):
+            if hasattr(qs, 'model') and hasattr(qs, 'query'):
+                info = {
+                    'index': i,
+                    'model': qs.model.__name__,
+                    'model_label': qs.model._meta.label,
+                    'query_where': str(qs.query.where) if hasattr(qs.query, 'where') else 'No where clause'
+                }
+                fast_delete_info.append(info)
+        
+        # Print for debugging (will show in test output)
+        print(f"\nFast delete queries for user1 deletion:")
+        for info in fast_delete_info:
+            print(f"  {info['index']}: {info['model']} - {info['query_where']}")
+        
+        # Verify we have the expected structure
+        self.assertGreater(len(fast_delete_info), 0, "Should have fast delete queries")
+
+
+class FastDeleteEdgeCasesTest(TransactionTestCase):
+    """Test edge cases for fast delete optimization."""
+    
+    def test_empty_fast_deletes_list(self):
+        """Test that empty fast_deletes list is handled correctly."""
+        collector = Collector(using='default')
+        # Don't collect anything
+        
+        # Should not raise any errors
+        try:
+            deleted_count, deleted_details = collector.delete()
+            self.assertEqual(deleted_count, 0)
+            self.assertEqual(deleted_details, {})
+        except Exception as e:
+            self.fail(f"Empty fast_deletes should not cause errors: {e}")
+    
+    def test_single_fast_delete_unchanged(self):
+        """Test that single fast delete queries are not affected by optimization."""
+        # Create a simple case with only one relationship
+        user = User.objects.create(username='single_user')
+        
+        # Create model with single FK (not multiple FKs to same model)
+        class SimpleModel(models.Model):
+            user = models.ForeignKey(User, on_delete=models.CASCADE)
+            class Meta:
+                app_label = 'delete_regress'
+        
+        collector = Collector(using='default')
+        collector.collect([user])
+        
+        # Should still work correctly
+        deleted_count, deleted_details = collector.delete()
+        self.assertGreaterEqual(deleted_count, 1)
