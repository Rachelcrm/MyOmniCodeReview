{
  "instance_id": "mwaskom__seaborn-3187",
  "model": "openrouter/anthropic/claude-sonnet-4",
  "response": "```\n<file>tests/test_core/test_scales_offset_bug.py</file>\n<original>\n# Empty if creating new file\n</original>\n<patched>\nimport pytest\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import ScalarFormatter\nfrom matplotlib.axis import Axis\n\nimport seaborn as sns\nimport seaborn.objects as so\nfrom seaborn._core.scales import Continuous, ContinuousBase\nfrom seaborn._core.properties import PointSize\n\n\nclass TestScalarFormatterOffsetBug:\n    \"\"\"Test suite for the ScalarFormatter offset bug in legend values.\"\"\"\n\n    @pytest.fixture\n    def large_value_data(self):\n        \"\"\"Create test data with large values that trigger ScalarFormatter offset.\"\"\"\n        np.random.seed(42)\n        n = 100\n        data = pd.DataFrame({\n            'x': np.random.normal(10, 2, n),\n            'y': np.random.normal(15, 3, n),\n            'category': np.random.choice(['A', 'B', 'C'], n),\n            'large_values': np.random.uniform(2000000, 6000000, n),  # Values in millions\n            'medium_values': np.random.uniform(2000, 6000, n),      # Values in thousands\n        })\n        return data\n\n    @pytest.fixture\n    def mock_axis_with_scalar_formatter(self):\n        \"\"\"Create a mock axis with ScalarFormatter that has an offset.\"\"\"\n        fig, ax = plt.subplots()\n        axis = ax.xaxis\n        \n        # Set up ScalarFormatter with offset\n        formatter = ScalarFormatter()\n        formatter.set_useOffset(True)\n        axis.set_major_formatter(formatter)\n        \n        # Set view interval to trigger offset\n        axis.set_view_interval(2000000, 6000000)\n        \n        # Force the formatter to calculate offset\n        locs = np.array([2000000, 3000000, 4000000, 5000000, 6000000])\n        formatter.format_ticks(locs)\n        \n        plt.close(fig)\n        return axis\n\n    def test_scalar_formatter_has_offset_with_large_values(self, mock_axis_with_scalar_formatter):\n        \"\"\"Test that ScalarFormatter creates an offset with large values.\"\"\"\n        formatter = mock_axis_with_scalar_formatter.major.formatter\n        \n        # Format some large values\n        locs = np.array([2000000, 3000000, 4000000, 5000000, 6000000])\n        labels = formatter.format_ticks(locs)\n        \n        # Check that formatter has an offset\n        offset = formatter.get_offset()\n        assert offset != '', \"ScalarFormatter should have an offset for large values\"\n        \n        # Check that labels are formatted with offset (should be smaller numbers)\n        # When offset is used, labels should be like ['2', '3', '4', '5', '6'] instead of full values\n        numeric_labels = [float(label) for label in labels if label.replace('.', '').replace('-', '').isdigit()]\n        assert all(val < 100 for val in numeric_labels), \"Labels should be small when offset is used\"\n\n    def test_continuous_scale_setup_without_offset_fix(self, large_value_data):\n        \"\"\"Test that demonstrates the bug: legend values are wrong when ScalarFormatter uses offset.\"\"\"\n        # Create a Continuous scale\n        scale = Continuous()\n        \n        # Create a mock property that requires legend\n        prop = PointSize()\n        prop.legend = True\n        \n        # Create axis with ScalarFormatter\n        fig, ax = plt.subplots()\n        axis = ax.xaxis\n        formatter = ScalarFormatter()\n        formatter.set_useOffset(True)\n        axis.set_major_formatter(formatter)\n        \n        # Setup the scale with large values\n        data = pd.Series(large_value_data['large_values'])\n        result_scale = scale._setup(data, prop, axis)\n        \n        # Check that legend was created\n        assert result_scale._legend is not None, \"Legend should be created\"\n        \n        locs, labels = result_scale._legend\n        \n        # This test demonstrates the bug: when ScalarFormatter uses offset,\n        # the legend locations should represent the actual data values,\n        # but currently they don't account for the offset\n        \n        # The bug is that locs contains the original large values,\n        # but the labels are formatted with offset, creating inconsistency\n        assert len(locs) > 0, \"Legend should have location values\"\n        assert len(labels) > 0, \"Legend should have label values\"\n        \n        # Check if any location value is in the millions (original data range)\n        has_large_locs = any(loc > 1000000 for loc in locs)\n        \n        # Check if labels represent small values (due to offset formatting)\n        numeric_labels = []\n        for label in labels:\n            try:\n                numeric_labels.append(float(label))\n            except ValueError:\n                pass\n        \n        has_small_labels = any(val < 100 for val in numeric_labels) if numeric_labels else False\n        \n        # This condition demonstrates the bug: large locations with small labels\n        if has_large_locs and has_small_labels:\n            pytest.fail(\n                f\"Bug detected: Legend locations {locs} are large values, \"\n                f\"but labels {labels} are small due to ScalarFormatter offset. \"\n                f\"This creates inconsistent legend values.\"\n            )\n        \n        plt.close(fig)\n\n    def test_continuous_scale_setup_with_medium_values_no_offset(self, large_value_data):\n        \"\"\"Test that medium values work correctly (no offset needed).\"\"\"\n        # Create a Continuous scale\n        scale = Continuous()\n        \n        # Create a mock property that requires legend\n        prop = PointSize()\n        prop.legend = True\n        \n        # Create axis with ScalarFormatter\n        fig, ax = plt.subplots()\n        axis = ax.xaxis\n        formatter = ScalarFormatter()\n        axis.set_major_formatter(formatter)\n        \n        # Setup the scale with medium values (shouldn't trigger offset)\n        data = pd.Series(large_value_data['medium_values'])\n        result_scale = scale._setup(data, prop, axis)\n        \n        # Check that legend was created\n        assert result_scale._legend is not None, \"Legend should be created\"\n        \n        locs, labels = result_scale._legend\n        \n        # With medium values, there should be no offset issue\n        assert len(locs) > 0, \"Legend should have location values\"\n        assert len(labels) > 0, \"Legend should have label values\"\n        \n        # Verify that locations and labels are consistent (no offset)\n        for i, (loc, label) in enumerate(zip(locs, labels)):\n            try:\n                label_value = float(label)\n                # For medium values without offset, location and label should be similar\n                assert abs(loc - label_value) < loc * 0.1, (\n                    f\"Location {loc} and label value {label_value} should be similar \"\n                    f\"when no offset is used\"\n                )\n            except ValueError:\n                # Skip non-numeric labels\n                pass\n        \n        plt.close(fig)\n\n    def test_seaborn_plot_with_large_values_demonstrates_bug(self, large_value_data):\n        \"\"\"Test using seaborn.objects Plot to demonstrate the bug in real usage.\"\"\"\n        # This test demonstrates the bug using the exact example from the issue\n        \n        # Create plot with large values for pointsize\n        plot = (\n            so.Plot(\n                large_value_data, \n                x=\"x\", \n                y=\"y\",\n                color=\"category\", \n                pointsize=\"large_values\"\n            )\n            .add(so.Dot())\n        )\n        \n        # Build the plot to trigger scale setup\n        try:\n            p = plot._plot()\n            \n            # Check if any legend was created for pointsize\n            # This is where the bug would manifest - legend values would be wrong\n            \n            # The bug would show up as legend values that don't match the actual data range\n            # For example, if data is in millions (2M-6M), legend might show 2-6\n            \n            # Clean up\n            plt.close('all')\n            \n        except Exception as e:\n            plt.close('all')\n            pytest.fail(f\"Plot creation failed: {e}\")\n\n    def test_scalar_formatter_offset_detection(self):\n        \"\"\"Test helper function to detect when ScalarFormatter has offset.\"\"\"\n        fig, ax = plt.subplots()\n        formatter = ScalarFormatter()\n        \n        # Test with small values (no offset expected)\n        small_values = np.array([1, 2, 3, 4, 5])\n        formatter.format_ticks(small_values)\n        offset_small = formatter.get_offset()\n        \n        # Test with large values (offset expected)\n        large_values = np.array([2000000, 3000000, 4000000, 5000000, 6000000])\n        formatter.set_useOffset(True)\n        formatter.format_ticks(large_values)\n        offset_large = formatter.get_offset()\n        \n        # Small values should not have offset\n        assert offset_small == '' or offset_small is None, \"Small values should not trigger offset\"\n        \n        # Large values should have offset when useOffset is True\n        # Note: This might depend on matplotlib version and rcParams\n        \n        plt.close(fig)\n\n    def test_legend_values_should_match_data_range(self, large_value_data):\n        \"\"\"Test that legend values should represent the actual data range.\"\"\"\n        # This test defines the expected behavior after the fix\n        \n        data_min = large_value_data['large_values'].min()\n        data_max = large_value_data['large_values'].max()\n        \n        # Create a Continuous scale\n        scale = Continuous()\n        \n        # Create a mock property that requires legend\n        prop = PointSize()\n        prop.legend = True\n        \n        # Create axis with ScalarFormatter\n        fig, ax = plt.subplots()\n        axis = ax.xaxis\n        formatter = ScalarFormatter()\n        formatter.set_useOffset(True)\n        axis.set_major_formatter(formatter)\n        \n        # Setup the scale with large values\n        data = pd.Series(large_value_data['large_values'])\n        result_scale = scale._setup(data, prop, axis)\n        \n        # After the fix, legend locations should be in the same range as the data\n        if result_scale._legend is not None:\n            locs, labels = result_scale._legend\n            \n            if locs:\n                legend_min = min(locs)\n                legend_max = max(locs)\n                \n                # Legend range should overlap significantly with data range\n                # Allow some tolerance for tick selection\n                assert legend_min >= data_min * 0.8, (\n                    f\"Legend minimum {legend_min} should be close to data minimum {data_min}\"\n                )\n                assert legend_max <= data_max * 1.2, (\n                    f\"Legend maximum {legend_max} should be close to data maximum {data_max}\"\n                )\n        \n        plt.close(fig)\n\n    @pytest.mark.parametrize(\"use_offset\", [True, False])\n    def test_scalar_formatter_offset_parameter(self, use_offset, large_value_data):\n        \"\"\"Test behavior with different offset settings.\"\"\"\n        # Create a Continuous scale\n        scale = Continuous()\n        \n        # Create a mock property that requires legend\n        prop = PointSize()\n        prop.legend = True\n        \n        # Create axis with ScalarFormatter\n        fig, ax = plt.subplots()\n        axis = ax.xaxis\n        formatter = ScalarFormatter()\n        formatter.set_useOffset(use_offset)\n        axis.set_major_formatter(formatter)\n        \n        # Setup the scale with large values\n        data = pd.Series(large_value_data['large_values'])\n        result_scale = scale._setup(data, prop, axis)\n        \n        # Check that legend was created\n        assert result_scale._legend is not None, \"Legend should be created\"\n        \n        locs, labels = result_scale._legend\n        assert len(locs) > 0, \"Legend should have location values\"\n        assert len(labels) > 0, \"Legend should have label values\"\n        \n        # The behavior should be consistent regardless of offset setting\n        # After the fix, legend values should always represent actual data values\n        \n        plt.close(fig)\n</patched>\n</file>\n```",
  "patch": "--- a/tests/test_core/test_scales_offset_bug.py\n+++ b/tests/test_core/test_scales_offset_bug.py\n-# Empty if creating new file\n+import pytest\n+import numpy as np\n+import pandas as pd\n+import matplotlib.pyplot as plt\n+from matplotlib.ticker import ScalarFormatter\n+from matplotlib.axis import Axis\n+\n+import seaborn as sns\n+import seaborn.objects as so\n+from seaborn._core.scales import Continuous, ContinuousBase\n+from seaborn._core.properties import PointSize\n+\n+\n+class TestScalarFormatterOffsetBug:\n+    \"\"\"Test suite for the ScalarFormatter offset bug in legend values.\"\"\"\n+\n+    @pytest.fixture\n+    def large_value_data(self):\n+        \"\"\"Create test data with large values that trigger ScalarFormatter offset.\"\"\"\n+        np.random.seed(42)\n+        n = 100\n+        data = pd.DataFrame({\n+            'x': np.random.normal(10, 2, n),\n+            'y': np.random.normal(15, 3, n),\n+            'category': np.random.choice(['A', 'B', 'C'], n),\n+            'large_values': np.random.uniform(2000000, 6000000, n),  # Values in millions\n+            'medium_values': np.random.uniform(2000, 6000, n),      # Values in thousands\n+        })\n+        return data\n+\n+    @pytest.fixture\n+    def mock_axis_with_scalar_formatter(self):\n+        \"\"\"Create a mock axis with ScalarFormatter that has an offset.\"\"\"\n+        fig, ax = plt.subplots()\n+        axis = ax.xaxis\n+        \n+        # Set up ScalarFormatter with offset\n+        formatter = ScalarFormatter()\n+        formatter.set_useOffset(True)\n+        axis.set_major_formatter(formatter)\n+        \n+        # Set view interval to trigger offset\n+        axis.set_view_interval(2000000, 6000000)\n+        \n+        # Force the formatter to calculate offset\n+        locs = np.array([2000000, 3000000, 4000000, 5000000, 6000000])\n+        formatter.format_ticks(locs)\n+        \n+        plt.close(fig)\n+        return axis\n+\n+    def test_scalar_formatter_has_offset_with_large_values(self, mock_axis_with_scalar_formatter):\n+        \"\"\"Test that ScalarFormatter creates an offset with large values.\"\"\"\n+        formatter = mock_axis_with_scalar_formatter.major.formatter\n+        \n+        # Format some large values\n+        locs = np.array([2000000, 3000000, 4000000, 5000000, 6000000])\n+        labels = formatter.format_ticks(locs)\n+        \n+        # Check that formatter has an offset\n+        offset = formatter.get_offset()\n+        assert offset != '', \"ScalarFormatter should have an offset for large values\"\n+        \n+        # Check that labels are formatted with offset (should be smaller numbers)\n+        # When offset is used, labels should be like ['2', '3', '4', '5', '6'] instead of full values\n+        numeric_labels = [float(label) for label in labels if label.replace('.', '').replace('-', '').isdigit()]\n+        assert all(val < 100 for val in numeric_labels), \"Labels should be small when offset is used\"\n+\n+    def test_continuous_scale_setup_without_offset_fix(self, large_value_data):\n+        \"\"\"Test that demonstrates the bug: legend values are wrong when ScalarFormatter uses offset.\"\"\"\n+        # Create a Continuous scale\n+        scale = Continuous()\n+        \n+        # Create a mock property that requires legend\n+        prop = PointSize()\n+        prop.legend = True\n+        \n+        # Create axis with ScalarFormatter\n+        fig, ax = plt.subplots()\n+        axis = ax.xaxis\n+        formatter = ScalarFormatter()\n+        formatter.set_useOffset(True)\n+        axis.set_major_formatter(formatter)\n+        \n+        # Setup the scale with large values\n+        data = pd.Series(large_value_data['large_values'])\n+        result_scale = scale._setup(data, prop, axis)\n+        \n+        # Check that legend was created\n+        assert result_scale._legend is not None, \"Legend should be created\"\n+        \n+        locs, labels = result_scale._legend\n+        \n+        # This test demonstrates the bug: when ScalarFormatter uses offset,\n+        # the legend locations should represent the actual data values,\n+        # but currently they don't account for the offset\n+        \n+        # The bug is that locs contains the original large values,\n+        # but the labels are formatted with offset, creating inconsistency\n+        assert len(locs) > 0, \"Legend should have location values\"\n+        assert len(labels) > 0, \"Legend should have label values\"\n+        \n+        # Check if any location value is in the millions (original data range)\n+        has_large_locs = any(loc > 1000000 for loc in locs)\n+        \n+        # Check if labels represent small values (due to offset formatting)\n+        numeric_labels = []\n+        for label in labels:\n+            try:\n+                numeric_labels.append(float(label))\n+            except ValueError:\n+                pass\n+        \n+        has_small_labels = any(val < 100 for val in numeric_labels) if numeric_labels else False\n+        \n+        # This condition demonstrates the bug: large locations with small labels\n+        if has_large_locs and has_small_labels:\n+            pytest.fail(\n+                f\"Bug detected: Legend locations {locs} are large values, \"\n+                f\"but labels {labels} are small due to ScalarFormatter offset. \"\n+                f\"This creates inconsistent legend values.\"\n+            )\n+        \n+        plt.close(fig)\n+\n+    def test_continuous_scale_setup_with_medium_values_no_offset(self, large_value_data):\n+        \"\"\"Test that medium values work correctly (no offset needed).\"\"\"\n+        # Create a Continuous scale\n+        scale = Continuous()\n+        \n+        # Create a mock property that requires legend\n+        prop = PointSize()\n+        prop.legend = True\n+        \n+        # Create axis with ScalarFormatter\n+        fig, ax = plt.subplots()\n+        axis = ax.xaxis\n+        formatter = ScalarFormatter()\n+        axis.set_major_formatter(formatter)\n+        \n+        # Setup the scale with medium values (shouldn't trigger offset)\n+        data = pd.Series(large_value_data['medium_values'])\n+        result_scale = scale._setup(data, prop, axis)\n+        \n+        # Check that legend was created\n+        assert result_scale._legend is not None, \"Legend should be created\"\n+        \n+        locs, labels = result_scale._legend\n+        \n+        # With medium values, there should be no offset issue\n+        assert len(locs) > 0, \"Legend should have location values\"\n+        assert len(labels) > 0, \"Legend should have label values\"\n+        \n+        # Verify that locations and labels are consistent (no offset)\n+        for i, (loc, label) in enumerate(zip(locs, labels)):\n+            try:\n+                label_value = float(label)\n+                # For medium values without offset, location and label should be similar\n+                assert abs(loc - label_value) < loc * 0.1, (\n+                    f\"Location {loc} and label value {label_value} should be similar \"\n+                    f\"when no offset is used\"\n+                )\n+            except ValueError:\n+                # Skip non-numeric labels\n+                pass\n+        \n+        plt.close(fig)\n+\n+    def test_seaborn_plot_with_large_values_demonstrates_bug(self, large_value_data):\n+        \"\"\"Test using seaborn.objects Plot to demonstrate the bug in real usage.\"\"\"\n+        # This test demonstrates the bug using the exact example from the issue\n+        \n+        # Create plot with large values for pointsize\n+        plot = (\n+            so.Plot(\n+                large_value_data, \n+                x=\"x\", \n+                y=\"y\",\n+                color=\"category\", \n+                pointsize=\"large_values\"\n+            )\n+            .add(so.Dot())\n+        )\n+        \n+        # Build the plot to trigger scale setup\n+        try:\n+            p = plot._plot()\n+            \n+            # Check if any legend was created for pointsize\n+            # This is where the bug would manifest - legend values would be wrong\n+            \n+            # The bug would show up as legend values that don't match the actual data range\n+            # For example, if data is in millions (2M-6M), legend might show 2-6\n+            \n+            # Clean up\n+            plt.close('all')\n+            \n+        except Exception as e:\n+            plt.close('all')\n+            pytest.fail(f\"Plot creation failed: {e}\")\n+\n+    def test_scalar_formatter_offset_detection(self):\n+        \"\"\"Test helper function to detect when ScalarFormatter has offset.\"\"\"\n+        fig, ax = plt.subplots()\n+        formatter = ScalarFormatter()\n+        \n+        # Test with small values (no offset expected)\n+        small_values = np.array([1, 2, 3, 4, 5])\n+        formatter.format_ticks(small_values)\n+        offset_small = formatter.get_offset()\n+        \n+        # Test with large values (offset expected)\n+        large_values = np.array([2000000, 3000000, 4000000, 5000000, 6000000])\n+        formatter.set_useOffset(True)\n+        formatter.format_ticks(large_values)\n+        offset_large = formatter.get_offset()\n+        \n+        # Small values should not have offset\n+        assert offset_small == '' or offset_small is None, \"Small values should not trigger offset\"\n+        \n+        # Large values should have offset when useOffset is True\n+        # Note: This might depend on matplotlib version and rcParams\n+        \n+        plt.close(fig)\n+\n+    def test_legend_values_should_match_data_range(self, large_value_data):\n+        \"\"\"Test that legend values should represent the actual data range.\"\"\"\n+        # This test defines the expected behavior after the fix\n+        \n+        data_min = large_value_data['large_values'].min()\n+        data_max = large_value_data['large_values'].max()\n+        \n+        # Create a Continuous scale\n+        scale = Continuous()\n+        \n+        # Create a mock property that requires legend\n+        prop = PointSize()\n+        prop.legend = True\n+        \n+        # Create axis with ScalarFormatter\n+        fig, ax = plt.subplots()\n+        axis = ax.xaxis\n+        formatter = ScalarFormatter()\n+        formatter.set_useOffset(True)\n+        axis.set_major_formatter(formatter)\n+        \n+        # Setup the scale with large values\n+        data = pd.Series(large_value_data['large_values'])\n+        result_scale = scale._setup(data, prop, axis)\n+        \n+        # After the fix, legend locations should be in the same range as the data\n+        if result_scale._legend is not None:\n+            locs, labels = result_scale._legend\n+            \n+            if locs:\n+                legend_min = min(locs)\n+                legend_max = max(locs)\n+                \n+                # Legend range should overlap significantly with data range\n+                # Allow some tolerance for tick selection\n+                assert legend_min >= data_min * 0.8, (\n+                    f\"Legend minimum {legend_min} should be close to data minimum {data_min}\"\n+                )\n+                assert legend_max <= data_max * 1.2, (\n+                    f\"Legend maximum {legend_max} should be close to data maximum {data_max}\"\n+                )\n+        \n+        plt.close(fig)\n+\n+    @pytest.mark.parametrize(\"use_offset\", [True, False])\n+    def test_scalar_formatter_offset_parameter(self, use_offset, large_value_data):\n+        \"\"\"Test behavior with different offset settings.\"\"\"\n+        # Create a Continuous scale\n+        scale = Continuous()\n+        \n+        # Create a mock property that requires legend\n+        prop = PointSize()\n+        prop.legend = True\n+        \n+        # Create axis with ScalarFormatter\n+        fig, ax = plt.subplots()\n+        axis = ax.xaxis\n+        formatter = ScalarFormatter()\n+        formatter.set_useOffset(use_offset)\n+        axis.set_major_formatter(formatter)\n+        \n+        # Setup the scale with large values\n+        data = pd.Series(large_value_data['large_values'])\n+        result_scale = scale._setup(data, prop, axis)\n+        \n+        # Check that legend was created\n+        assert result_scale._legend is not None, \"Legend should be created\"\n+        \n+        locs, labels = result_scale._legend\n+        assert len(locs) > 0, \"Legend should have location values\"\n+        assert len(labels) > 0, \"Legend should have label values\"\n+        \n+        # The behavior should be consistent regardless of offset setting\n+        # After the fix, legend values should always represent actual data values\n+        \n+        plt.close(fig)\n"
}