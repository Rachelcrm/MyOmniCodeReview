{
  "instance_id": "scrapy__scrapy-5917",
  "model": "openrouter/anthropic/claude-sonnet-4",
  "response": "```\n<file>tests/test_responsetypes.py</file>\n<original>\n# Empty if creating new file\n</original>\n<patched>\nimport pytest\nfrom scrapy.responsetypes import ResponseTypes\nfrom scrapy.http import Response, HtmlResponse, TextResponse\nfrom scrapy.utils.test import get_testdata\n\n\nclass TestResponseTypesNonUTF8ContentType:\n    \"\"\"Test ResponseTypes handling of non-UTF-8 encoded Content-Type headers.\"\"\"\n    \n    def setup_method(self):\n        self.response_types = ResponseTypes()\n    \n    def test_from_content_type_with_utf8_content_type(self):\n        \"\"\"Test that UTF-8 encoded Content-Type headers work correctly (baseline test).\"\"\"\n        content_type = b'text/html; charset=utf-8'\n        result = self.response_types.from_content_type(content_type)\n        assert result == HtmlResponse\n    \n    def test_from_content_type_with_latin1_content_type(self):\n        \"\"\"Test that Latin-1 encoded Content-Type headers work correctly.\"\"\"\n        # Create a Content-Type header with Latin-1 encoded characters\n        content_type = b'text/html; charset=iso-8859-1'\n        result = self.response_types.from_content_type(content_type)\n        assert result == HtmlResponse\n    \n    def test_from_content_type_with_windows1251_content_type(self):\n        \"\"\"Test that Windows-1251 encoded Content-Type headers work correctly.\n        \n        This reproduces the bug described in the issue where cp1251/windows-1251\n        encoded headers cause UnicodeDecodeError.\n        \"\"\"\n        # Create a Content-Type header that contains windows-1251 encoded bytes\n        # This simulates the problematic header from the issue\n        content_type = b'text/html; charset=\"windows-1251\"'\n        # Add some non-UTF-8 bytes that would cause the original bug\n        content_type_with_non_utf8 = content_type + b'\\xcf\\xf0\\xe0\\xe2\\xee'  # windows-1251 encoded text\n        \n        # This should not raise UnicodeDecodeError\n        result = self.response_types.from_content_type(content_type_with_non_utf8)\n        assert result == HtmlResponse\n    \n    def test_from_content_type_with_cp1251_bytes_in_header(self):\n        \"\"\"Test Content-Type header with cp1251 bytes that caused the original bug.\"\"\"\n        # Simulate the exact scenario from the bug report\n        # The byte 0xcf at position 33 that caused the UnicodeDecodeError\n        content_type = b'text/html; charset=\"windows-1251\"\\xcf'\n        \n        # This should not raise UnicodeDecodeError after the fix\n        result = self.response_types.from_content_type(content_type)\n        assert result == HtmlResponse\n    \n    def test_from_content_type_with_various_non_utf8_bytes(self):\n        \"\"\"Test Content-Type headers with various non-UTF-8 byte sequences.\"\"\"\n        test_cases = [\n            b'text/html\\x80\\x81\\x82',  # High-bit bytes\n            b'application/json\\xff\\xfe',  # More high-bit bytes\n            b'text/plain\\xa0\\xa1\\xa2',  # Latin-1 supplement range\n            b'text/xml\\xc0\\xc1\\xc2',   # Invalid UTF-8 sequences\n        ]\n        \n        for content_type in test_cases:\n            # Should not raise UnicodeDecodeError\n            result = self.response_types.from_content_type(content_type)\n            # Should return appropriate response class based on mimetype\n            assert issubclass(result, Response)\n    \n    def test_from_headers_with_non_utf8_content_type(self):\n        \"\"\"Test from_headers method with non-UTF-8 Content-Type header.\"\"\"\n        headers = {\n            b'Content-Type': b'text/html; charset=\"windows-1251\"\\xcf\\xf0'\n        }\n        \n        # This should not raise UnicodeDecodeError\n        result = self.response_types.from_headers(headers)\n        assert result == HtmlResponse\n    \n    def test_from_args_with_non_utf8_content_type_headers(self):\n        \"\"\"Test from_args method with headers containing non-UTF-8 Content-Type.\"\"\"\n        headers = {\n            b'Content-Type': b'application/json\\x80\\x81\\x82'\n        }\n        \n        # This should not raise UnicodeDecodeError\n        result = self.response_types.from_args(headers=headers)\n        assert result == TextResponse\n    \n    def test_mimetype_extraction_with_non_utf8_content_type(self):\n        \"\"\"Test that mimetype is correctly extracted even with non-UTF-8 bytes.\"\"\"\n        # Content-Type with valid mimetype but non-UTF-8 bytes after\n        content_type = b'application/xml; charset=windows-1251\\xcf\\xf0\\xe0'\n        \n        result = self.response_types.from_content_type(content_type)\n        # Should correctly identify as XML response despite non-UTF-8 bytes\n        from scrapy.http import XmlResponse\n        assert result == XmlResponse\n    \n    def test_content_type_with_encoding_parameter_non_utf8(self):\n        \"\"\"Test Content-Type with encoding parameter containing non-UTF-8 bytes.\"\"\"\n        content_type = b'text/html; charset=windows-1251; boundary=\\xcf\\xf0'\n        \n        # Should not raise UnicodeDecodeError and should return HtmlResponse\n        result = self.response_types.from_content_type(content_type)\n        assert result == HtmlResponse\n    \n    def test_empty_content_type_still_works(self):\n        \"\"\"Test that empty or None content type still works (regression test).\"\"\"\n        result = self.response_types.from_content_type(b'')\n        assert result == Response\n        \n        result = self.response_types.from_content_type(None)\n        assert result == Response\n\n\nclass TestResponseTypesNonUTF8Integration:\n    \"\"\"Integration tests simulating the full response processing pipeline.\"\"\"\n    \n    def setup_method(self):\n        self.response_types = ResponseTypes()\n    \n    def test_full_pipeline_with_problematic_headers(self):\n        \"\"\"Test the full pipeline that was failing in the original bug report.\"\"\"\n        # Simulate headers that would come from the problematic URL\n        headers = {\n            b'Content-Type': b'text/html; charset=\"windows-1251\"',\n            b'Content-Transfer-Encoding': b'quoted-printable',\n        }\n        \n        # Add some non-UTF-8 bytes to simulate the real-world scenario\n        headers[b'Content-Type'] += b'\\xcf\\xf0\\xe0\\xe2\\xee'\n        \n        # This should work without raising UnicodeDecodeError\n        result = self.response_types.from_args(\n            headers=headers,\n            url='http://pravo.gov.ru/proxy/ips/?savertf=&link_id=0&nd=128284801',\n            body=b'<html><body>Test</body></html>'\n        )\n        \n        assert result == HtmlResponse\n    \n    def test_bug_reproduction_scenario(self):\n        \"\"\"Reproduce the exact scenario from the bug report.\"\"\"\n        # This test should fail before the fix and pass after the fix\n        content_type = b'text/html; charset=\"windows-1251\"'\n        # Add the problematic byte that caused the original error\n        content_type_with_problem_byte = content_type + b'\\xcf'\n        \n        # Before fix: this would raise UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcf\n        # After fix: this should work correctly\n        try:\n            result = self.response_types.from_content_type(content_type_with_problem_byte)\n            assert result == HtmlResponse\n        except UnicodeDecodeError as e:\n            pytest.fail(f\"UnicodeDecodeError should not be raised after fix: {e}\")\n</patched>\n```",
  "patch": "--- a/tests/test_responsetypes.py\n+++ b/tests/test_responsetypes.py\n-# Empty if creating new file\n+import pytest\n+from scrapy.responsetypes import ResponseTypes\n+from scrapy.http import Response, HtmlResponse, TextResponse\n+from scrapy.utils.test import get_testdata\n+\n+\n+class TestResponseTypesNonUTF8ContentType:\n+    \"\"\"Test ResponseTypes handling of non-UTF-8 encoded Content-Type headers.\"\"\"\n+    \n+    def setup_method(self):\n+        self.response_types = ResponseTypes()\n+    \n+    def test_from_content_type_with_utf8_content_type(self):\n+        \"\"\"Test that UTF-8 encoded Content-Type headers work correctly (baseline test).\"\"\"\n+        content_type = b'text/html; charset=utf-8'\n+        result = self.response_types.from_content_type(content_type)\n+        assert result == HtmlResponse\n+    \n+    def test_from_content_type_with_latin1_content_type(self):\n+        \"\"\"Test that Latin-1 encoded Content-Type headers work correctly.\"\"\"\n+        # Create a Content-Type header with Latin-1 encoded characters\n+        content_type = b'text/html; charset=iso-8859-1'\n+        result = self.response_types.from_content_type(content_type)\n+        assert result == HtmlResponse\n+    \n+    def test_from_content_type_with_windows1251_content_type(self):\n+        \"\"\"Test that Windows-1251 encoded Content-Type headers work correctly.\n+        \n+        This reproduces the bug described in the issue where cp1251/windows-1251\n+        encoded headers cause UnicodeDecodeError.\n+        \"\"\"\n+        # Create a Content-Type header that contains windows-1251 encoded bytes\n+        # This simulates the problematic header from the issue\n+        content_type = b'text/html; charset=\"windows-1251\"'\n+        # Add some non-UTF-8 bytes that would cause the original bug\n+        content_type_with_non_utf8 = content_type + b'\\xcf\\xf0\\xe0\\xe2\\xee'  # windows-1251 encoded text\n+        \n+        # This should not raise UnicodeDecodeError\n+        result = self.response_types.from_content_type(content_type_with_non_utf8)\n+        assert result == HtmlResponse\n+    \n+    def test_from_content_type_with_cp1251_bytes_in_header(self):\n+        \"\"\"Test Content-Type header with cp1251 bytes that caused the original bug.\"\"\"\n+        # Simulate the exact scenario from the bug report\n+        # The byte 0xcf at position 33 that caused the UnicodeDecodeError\n+        content_type = b'text/html; charset=\"windows-1251\"\\xcf'\n+        \n+        # This should not raise UnicodeDecodeError after the fix\n+        result = self.response_types.from_content_type(content_type)\n+        assert result == HtmlResponse\n+    \n+    def test_from_content_type_with_various_non_utf8_bytes(self):\n+        \"\"\"Test Content-Type headers with various non-UTF-8 byte sequences.\"\"\"\n+        test_cases = [\n+            b'text/html\\x80\\x81\\x82',  # High-bit bytes\n+            b'application/json\\xff\\xfe',  # More high-bit bytes\n+            b'text/plain\\xa0\\xa1\\xa2',  # Latin-1 supplement range\n+            b'text/xml\\xc0\\xc1\\xc2',   # Invalid UTF-8 sequences\n+        ]\n+        \n+        for content_type in test_cases:\n+            # Should not raise UnicodeDecodeError\n+            result = self.response_types.from_content_type(content_type)\n+            # Should return appropriate response class based on mimetype\n+            assert issubclass(result, Response)\n+    \n+    def test_from_headers_with_non_utf8_content_type(self):\n+        \"\"\"Test from_headers method with non-UTF-8 Content-Type header.\"\"\"\n+        headers = {\n+            b'Content-Type': b'text/html; charset=\"windows-1251\"\\xcf\\xf0'\n+        }\n+        \n+        # This should not raise UnicodeDecodeError\n+        result = self.response_types.from_headers(headers)\n+        assert result == HtmlResponse\n+    \n+    def test_from_args_with_non_utf8_content_type_headers(self):\n+        \"\"\"Test from_args method with headers containing non-UTF-8 Content-Type.\"\"\"\n+        headers = {\n+            b'Content-Type': b'application/json\\x80\\x81\\x82'\n+        }\n+        \n+        # This should not raise UnicodeDecodeError\n+        result = self.response_types.from_args(headers=headers)\n+        assert result == TextResponse\n+    \n+    def test_mimetype_extraction_with_non_utf8_content_type(self):\n+        \"\"\"Test that mimetype is correctly extracted even with non-UTF-8 bytes.\"\"\"\n+        # Content-Type with valid mimetype but non-UTF-8 bytes after\n+        content_type = b'application/xml; charset=windows-1251\\xcf\\xf0\\xe0'\n+        \n+        result = self.response_types.from_content_type(content_type)\n+        # Should correctly identify as XML response despite non-UTF-8 bytes\n+        from scrapy.http import XmlResponse\n+        assert result == XmlResponse\n+    \n+    def test_content_type_with_encoding_parameter_non_utf8(self):\n+        \"\"\"Test Content-Type with encoding parameter containing non-UTF-8 bytes.\"\"\"\n+        content_type = b'text/html; charset=windows-1251; boundary=\\xcf\\xf0'\n+        \n+        # Should not raise UnicodeDecodeError and should return HtmlResponse\n+        result = self.response_types.from_content_type(content_type)\n+        assert result == HtmlResponse\n+    \n+    def test_empty_content_type_still_works(self):\n+        \"\"\"Test that empty or None content type still works (regression test).\"\"\"\n+        result = self.response_types.from_content_type(b'')\n+        assert result == Response\n+        \n+        result = self.response_types.from_content_type(None)\n+        assert result == Response\n+\n+\n+class TestResponseTypesNonUTF8Integration:\n+    \"\"\"Integration tests simulating the full response processing pipeline.\"\"\"\n+    \n+    def setup_method(self):\n+        self.response_types = ResponseTypes()\n+    \n+    def test_full_pipeline_with_problematic_headers(self):\n+        \"\"\"Test the full pipeline that was failing in the original bug report.\"\"\"\n+        # Simulate headers that would come from the problematic URL\n+        headers = {\n+            b'Content-Type': b'text/html; charset=\"windows-1251\"',\n+            b'Content-Transfer-Encoding': b'quoted-printable',\n+        }\n+        \n+        # Add some non-UTF-8 bytes to simulate the real-world scenario\n+        headers[b'Content-Type'] += b'\\xcf\\xf0\\xe0\\xe2\\xee'\n+        \n+        # This should work without raising UnicodeDecodeError\n+        result = self.response_types.from_args(\n+            headers=headers,\n+            url='http://pravo.gov.ru/proxy/ips/?savertf=&link_id=0&nd=128284801',\n+            body=b'<html><body>Test</body></html>'\n+        )\n+        \n+        assert result == HtmlResponse\n+    \n+    def test_bug_reproduction_scenario(self):\n+        \"\"\"Reproduce the exact scenario from the bug report.\"\"\"\n+        # This test should fail before the fix and pass after the fix\n+        content_type = b'text/html; charset=\"windows-1251\"'\n+        # Add the problematic byte that caused the original error\n+        content_type_with_problem_byte = content_type + b'\\xcf'\n+        \n+        # Before fix: this would raise UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcf\n+        # After fix: this should work correctly\n+        try:\n+            result = self.response_types.from_content_type(content_type_with_problem_byte)\n+            assert result == HtmlResponse\n+        except UnicodeDecodeError as e:\n+            pytest.fail(f\"UnicodeDecodeError should not be raised after fix: {e}\")\n"
}