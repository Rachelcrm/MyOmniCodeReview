{
  "instance_id": "scikit-learn__scikit-learn-12682",
  "model": "openrouter/anthropic/claude-sonnet-4",
  "response": "```\n<file>sklearn/decomposition/tests/test_dict_learning.py</file>\n<original>\n# This will be added to the existing test file\n</original>\n<patched>\nimport pytest\nimport numpy as np\nimport warnings\nfrom sklearn.decomposition import SparseCoder\nfrom sklearn.linear_model import Lasso\nfrom sklearn.exceptions import ConvergenceWarning\n\n\ndef test_sparse_coder_max_iter_parameter():\n    \"\"\"Test that SparseCoder accepts and uses max_iter parameter.\"\"\"\n    # Create a simple dictionary and data\n    n_components, n_features = 5, 10\n    n_samples = 8\n    \n    rng = np.random.RandomState(42)\n    dictionary = rng.randn(n_components, n_features)\n    X = rng.randn(n_samples, n_features)\n    \n    # Test that SparseCoder accepts max_iter parameter\n    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', max_iter=500)\n    assert hasattr(coder, 'max_iter')\n    assert coder.max_iter == 500\n    \n    # Test default value\n    coder_default = SparseCoder(dictionary, transform_algorithm='lasso_cd')\n    assert hasattr(coder_default, 'max_iter')\n    assert coder_default.max_iter == 1000\n\n\ndef test_sparse_coder_max_iter_convergence_warning():\n    \"\"\"Test that SparseCoder with low max_iter produces convergence warning.\"\"\"\n    # Create a dictionary and data that will likely not converge with few iterations\n    n_components, n_features = 10, 20\n    n_samples = 15\n    \n    rng = np.random.RandomState(42)\n    dictionary = rng.randn(n_components, n_features)\n    X = rng.randn(n_samples, n_features) * 10  # Scale up to make convergence harder\n    \n    # Test with very low max_iter should produce warning\n    coder_low_iter = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n                                max_iter=1, transform_alpha=0.1)\n    \n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(\"always\")\n        coder_low_iter.transform(X)\n        # Should have at least one convergence warning\n        convergence_warnings = [warning for warning in w \n                              if issubclass(warning.category, ConvergenceWarning)]\n        assert len(convergence_warnings) > 0\n\n\ndef test_sparse_coder_max_iter_no_warning_with_sufficient_iterations():\n    \"\"\"Test that SparseCoder with sufficient max_iter doesn't produce convergence warning.\"\"\"\n    # Create a simple dictionary and data\n    n_components, n_features = 5, 10\n    n_samples = 8\n    \n    rng = np.random.RandomState(42)\n    dictionary = rng.randn(n_components, n_features)\n    X = rng.randn(n_samples, n_features)\n    \n    # Test with high max_iter should not produce warning\n    coder_high_iter = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n                                 max_iter=5000, transform_alpha=0.1)\n    \n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(\"always\")\n        result = coder_high_iter.transform(X)\n        # Should have no convergence warnings\n        convergence_warnings = [warning for warning in w \n                              if issubclass(warning.category, ConvergenceWarning)]\n        assert len(convergence_warnings) == 0\n        assert result.shape == (n_samples, n_components)\n\n\ndef test_sparse_coder_max_iter_different_algorithms():\n    \"\"\"Test that max_iter parameter only affects lasso_cd algorithm.\"\"\"\n    n_components, n_features = 5, 10\n    n_samples = 8\n    \n    rng = np.random.RandomState(42)\n    dictionary = rng.randn(n_components, n_features)\n    X = rng.randn(n_samples, n_features)\n    \n    # Test with different algorithms - max_iter should be accepted but only used for lasso_cd\n    algorithms = ['omp', 'lasso_lars', 'lars', 'threshold']\n    \n    for algorithm in algorithms:\n        if algorithm == 'threshold':\n            coder = SparseCoder(dictionary, transform_algorithm=algorithm, \n                              max_iter=100, transform_alpha=0.1)\n        else:\n            coder = SparseCoder(dictionary, transform_algorithm=algorithm, \n                              max_iter=100, transform_n_nonzero_coefs=3)\n        \n        assert hasattr(coder, 'max_iter')\n        assert coder.max_iter == 100\n        \n        # Should not raise any errors\n        result = coder.transform(X)\n        assert result.shape == (n_samples, n_components)\n\n\ndef test_sparse_coder_max_iter_backward_compatibility():\n    \"\"\"Test that existing code without max_iter parameter still works.\"\"\"\n    n_components, n_features = 5, 10\n    n_samples = 8\n    \n    rng = np.random.RandomState(42)\n    dictionary = rng.randn(n_components, n_features)\n    X = rng.randn(n_samples, n_features)\n    \n    # Test that old code without max_iter still works\n    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n                       transform_alpha=0.1)\n    \n    result = coder.transform(X)\n    assert result.shape == (n_samples, n_components)\n    assert coder.max_iter == 1000  # Default value\n\n\ndef test_sparse_coder_max_iter_parameter_validation():\n    \"\"\"Test that max_iter parameter is properly validated.\"\"\"\n    n_components, n_features = 5, 10\n    \n    rng = np.random.RandomState(42)\n    dictionary = rng.randn(n_components, n_features)\n    \n    # Test with valid max_iter values\n    valid_values = [1, 100, 1000, 5000]\n    for max_iter in valid_values:\n        coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n                           max_iter=max_iter)\n        assert coder.max_iter == max_iter\n\n\ndef test_sparse_coder_max_iter_reproduces_original_issue():\n    \"\"\"Test that reproduces the original issue from the bug report.\"\"\"\n    # This test should fail before the fix and pass after the fix\n    n_components, n_features = 10, 20\n    n_samples = 15\n    \n    rng = np.random.RandomState(42)\n    # Create a dictionary and data that will likely not converge with default iterations\n    dictionary = rng.randn(n_components, n_features)\n    X = rng.randn(n_samples, n_features) * 5\n    \n    # Before fix: SparseCoder doesn't accept max_iter, uses default 1000\n    # After fix: SparseCoder should accept max_iter and use it\n    \n    # Test that we can now specify max_iter to avoid convergence warnings\n    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n                       max_iter=10000, transform_alpha=0.01)\n    \n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(\"always\")\n        result = coder.transform(X)\n        \n        # With sufficient iterations, should have fewer or no convergence warnings\n        convergence_warnings = [warning for warning in w \n                              if issubclass(warning.category, ConvergenceWarning)]\n        \n        # The key test: we should be able to control max_iter\n        assert hasattr(coder, 'max_iter')\n        assert coder.max_iter == 10000\n        assert result.shape == (n_samples, n_components)\n\n\ndef test_sparse_coder_max_iter_integration_with_lasso():\n    \"\"\"Test that max_iter is properly passed to underlying Lasso estimator.\"\"\"\n    # This test verifies the integration between SparseCoder and Lasso\n    n_components, n_features = 5, 10\n    n_samples = 8\n    \n    rng = np.random.RandomState(42)\n    dictionary = rng.randn(n_components, n_features)\n    X = rng.randn(n_samples, n_features)\n    \n    # Create SparseCoder with specific max_iter\n    max_iter_value = 2000\n    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n                       max_iter=max_iter_value, transform_alpha=0.1)\n    \n    # Transform should work without issues\n    result = coder.transform(X)\n    assert result.shape == (n_samples, n_components)\n    \n    # Verify that the max_iter is stored correctly\n    assert coder.max_iter == max_iter_value\n</patched>\n```",
  "patch": "--- a/sklearn/decomposition/tests/test_dict_learning.py\n+++ b/sklearn/decomposition/tests/test_dict_learning.py\n-# This will be added to the existing test file\n+import pytest\n+import numpy as np\n+import warnings\n+from sklearn.decomposition import SparseCoder\n+from sklearn.linear_model import Lasso\n+from sklearn.exceptions import ConvergenceWarning\n+\n+\n+def test_sparse_coder_max_iter_parameter():\n+    \"\"\"Test that SparseCoder accepts and uses max_iter parameter.\"\"\"\n+    # Create a simple dictionary and data\n+    n_components, n_features = 5, 10\n+    n_samples = 8\n+    \n+    rng = np.random.RandomState(42)\n+    dictionary = rng.randn(n_components, n_features)\n+    X = rng.randn(n_samples, n_features)\n+    \n+    # Test that SparseCoder accepts max_iter parameter\n+    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', max_iter=500)\n+    assert hasattr(coder, 'max_iter')\n+    assert coder.max_iter == 500\n+    \n+    # Test default value\n+    coder_default = SparseCoder(dictionary, transform_algorithm='lasso_cd')\n+    assert hasattr(coder_default, 'max_iter')\n+    assert coder_default.max_iter == 1000\n+\n+\n+def test_sparse_coder_max_iter_convergence_warning():\n+    \"\"\"Test that SparseCoder with low max_iter produces convergence warning.\"\"\"\n+    # Create a dictionary and data that will likely not converge with few iterations\n+    n_components, n_features = 10, 20\n+    n_samples = 15\n+    \n+    rng = np.random.RandomState(42)\n+    dictionary = rng.randn(n_components, n_features)\n+    X = rng.randn(n_samples, n_features) * 10  # Scale up to make convergence harder\n+    \n+    # Test with very low max_iter should produce warning\n+    coder_low_iter = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n+                                max_iter=1, transform_alpha=0.1)\n+    \n+    with warnings.catch_warnings(record=True) as w:\n+        warnings.simplefilter(\"always\")\n+        coder_low_iter.transform(X)\n+        # Should have at least one convergence warning\n+        convergence_warnings = [warning for warning in w \n+                              if issubclass(warning.category, ConvergenceWarning)]\n+        assert len(convergence_warnings) > 0\n+\n+\n+def test_sparse_coder_max_iter_no_warning_with_sufficient_iterations():\n+    \"\"\"Test that SparseCoder with sufficient max_iter doesn't produce convergence warning.\"\"\"\n+    # Create a simple dictionary and data\n+    n_components, n_features = 5, 10\n+    n_samples = 8\n+    \n+    rng = np.random.RandomState(42)\n+    dictionary = rng.randn(n_components, n_features)\n+    X = rng.randn(n_samples, n_features)\n+    \n+    # Test with high max_iter should not produce warning\n+    coder_high_iter = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n+                                 max_iter=5000, transform_alpha=0.1)\n+    \n+    with warnings.catch_warnings(record=True) as w:\n+        warnings.simplefilter(\"always\")\n+        result = coder_high_iter.transform(X)\n+        # Should have no convergence warnings\n+        convergence_warnings = [warning for warning in w \n+                              if issubclass(warning.category, ConvergenceWarning)]\n+        assert len(convergence_warnings) == 0\n+        assert result.shape == (n_samples, n_components)\n+\n+\n+def test_sparse_coder_max_iter_different_algorithms():\n+    \"\"\"Test that max_iter parameter only affects lasso_cd algorithm.\"\"\"\n+    n_components, n_features = 5, 10\n+    n_samples = 8\n+    \n+    rng = np.random.RandomState(42)\n+    dictionary = rng.randn(n_components, n_features)\n+    X = rng.randn(n_samples, n_features)\n+    \n+    # Test with different algorithms - max_iter should be accepted but only used for lasso_cd\n+    algorithms = ['omp', 'lasso_lars', 'lars', 'threshold']\n+    \n+    for algorithm in algorithms:\n+        if algorithm == 'threshold':\n+            coder = SparseCoder(dictionary, transform_algorithm=algorithm, \n+                              max_iter=100, transform_alpha=0.1)\n+        else:\n+            coder = SparseCoder(dictionary, transform_algorithm=algorithm, \n+                              max_iter=100, transform_n_nonzero_coefs=3)\n+        \n+        assert hasattr(coder, 'max_iter')\n+        assert coder.max_iter == 100\n+        \n+        # Should not raise any errors\n+        result = coder.transform(X)\n+        assert result.shape == (n_samples, n_components)\n+\n+\n+def test_sparse_coder_max_iter_backward_compatibility():\n+    \"\"\"Test that existing code without max_iter parameter still works.\"\"\"\n+    n_components, n_features = 5, 10\n+    n_samples = 8\n+    \n+    rng = np.random.RandomState(42)\n+    dictionary = rng.randn(n_components, n_features)\n+    X = rng.randn(n_samples, n_features)\n+    \n+    # Test that old code without max_iter still works\n+    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n+                       transform_alpha=0.1)\n+    \n+    result = coder.transform(X)\n+    assert result.shape == (n_samples, n_components)\n+    assert coder.max_iter == 1000  # Default value\n+\n+\n+def test_sparse_coder_max_iter_parameter_validation():\n+    \"\"\"Test that max_iter parameter is properly validated.\"\"\"\n+    n_components, n_features = 5, 10\n+    \n+    rng = np.random.RandomState(42)\n+    dictionary = rng.randn(n_components, n_features)\n+    \n+    # Test with valid max_iter values\n+    valid_values = [1, 100, 1000, 5000]\n+    for max_iter in valid_values:\n+        coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n+                           max_iter=max_iter)\n+        assert coder.max_iter == max_iter\n+\n+\n+def test_sparse_coder_max_iter_reproduces_original_issue():\n+    \"\"\"Test that reproduces the original issue from the bug report.\"\"\"\n+    # This test should fail before the fix and pass after the fix\n+    n_components, n_features = 10, 20\n+    n_samples = 15\n+    \n+    rng = np.random.RandomState(42)\n+    # Create a dictionary and data that will likely not converge with default iterations\n+    dictionary = rng.randn(n_components, n_features)\n+    X = rng.randn(n_samples, n_features) * 5\n+    \n+    # Before fix: SparseCoder doesn't accept max_iter, uses default 1000\n+    # After fix: SparseCoder should accept max_iter and use it\n+    \n+    # Test that we can now specify max_iter to avoid convergence warnings\n+    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n+                       max_iter=10000, transform_alpha=0.01)\n+    \n+    with warnings.catch_warnings(record=True) as w:\n+        warnings.simplefilter(\"always\")\n+        result = coder.transform(X)\n+        \n+        # With sufficient iterations, should have fewer or no convergence warnings\n+        convergence_warnings = [warning for warning in w \n+                              if issubclass(warning.category, ConvergenceWarning)]\n+        \n+        # The key test: we should be able to control max_iter\n+        assert hasattr(coder, 'max_iter')\n+        assert coder.max_iter == 10000\n+        assert result.shape == (n_samples, n_components)\n+\n+\n+def test_sparse_coder_max_iter_integration_with_lasso():\n+    \"\"\"Test that max_iter is properly passed to underlying Lasso estimator.\"\"\"\n+    # This test verifies the integration between SparseCoder and Lasso\n+    n_components, n_features = 5, 10\n+    n_samples = 8\n+    \n+    rng = np.random.RandomState(42)\n+    dictionary = rng.randn(n_components, n_features)\n+    X = rng.randn(n_samples, n_features)\n+    \n+    # Create SparseCoder with specific max_iter\n+    max_iter_value = 2000\n+    coder = SparseCoder(dictionary, transform_algorithm='lasso_cd', \n+                       max_iter=max_iter_value, transform_alpha=0.1)\n+    \n+    # Transform should work without issues\n+    result = coder.transform(X)\n+    assert result.shape == (n_samples, n_components)\n+    \n+    # Verify that the max_iter is stored correctly\n+    assert coder.max_iter == max_iter_value\n"
}