{
  "patch": "diff --git a/youtube_dl/extractor/common.py b/youtube_dl/extractor/common.py\nindex 0e5dfd8fa..24782ee6a 100644\n--- a/youtube_dl/extractor/common.py\n+++ b/youtube_dl/extractor/common.py\n@@ -578,9 +578,9 @@ class InfoExtractor(object):\n         except ExtractorError:\n             raise\n         except compat_http_client.IncompleteRead as e:\n-            raise ExtractorError('A network error has occurred.', cause=e, expected=True)\n+            raise ExtractorError('A network error has occurred.', cause=e, expected=True) from e\n         except (KeyError, StopIteration) as e:\n-            raise ExtractorError('An extractor error has occurred.', cause=e)\n+            raise ExtractorError('An extractor error has occurred.', cause=e) from e\n \n     def __maybe_fake_ip_and_retry(self, countries):\n         if (not self._downloader.params.get('geo_bypass_country', None)\n@@ -611,11 +611,11 @@ class InfoExtractor(object):\n \n     def _real_initialize(self):\n         \"\"\"Real initialization process. Redefine in subclasses.\"\"\"\n-        pass\n+        ...\n \n     def _real_extract(self, url):\n         \"\"\"Real extraction process. Redefine in subclasses.\"\"\"\n-        pass\n+        ...\n \n     @classmethod\n     def ie_key(cls):\n@@ -640,12 +640,14 @@ class InfoExtractor(object):\n         else:\n             assert False\n \n-    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers={}, query={}, expected_status=None):\n+    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers=None, query=None, expected_status=None):\n         \"\"\"\n         Return the response handle.\n \n         See _download_webpage docstring for arguments specification.\n         \"\"\"\n+        headers = headers or {}\n+        query = query or {}\n         if note is None:\n             self.report_download_webpage(video_id)\n         elif note is not False:\n@@ -693,17 +695,19 @@ class InfoExtractor(object):\n \n             errmsg = '%s: %s' % (errnote, error_to_compat_str(err))\n             if fatal:\n-                raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)\n+                raise ExtractorError(errmsg, sys.exc_info()[2], cause=err) from err\n             else:\n                 self._downloader.report_warning(errmsg)\n                 return False\n \n-    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers={}, query={}, expected_status=None):\n+    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers=None, query=None, expected_status=None):\n         \"\"\"\n         Return a tuple (page content as string, URL handle).\n \n         See _download_webpage docstring for arguments specification.\n         \"\"\"\n+        headers = headers or {}\n+        query = query or {}\n         # Strip hashes from the URL (#1038)\n         if isinstance(url_or_request, (compat_str, str)):\n             url_or_request = url_or_request.partition('#')[0]\n@@ -760,7 +764,7 @@ class InfoExtractor(object):\n                 'Visit http://blocklist.rkn.gov.ru/ for a block reason.',\n                 expected=True)\n \n-    def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None):\n+    def _webpage_read_content(self, urlh, _url_or_request, _video_id, _note=None, _errnote=None, _fatal=True, prefix=None, encoding=None):\n         content_type = urlh.headers.get('Content-Type', '')\n         webpage_bytes = urlh.read()\n         if prefix is not None:\n@@ -772,7 +776,7 @@ class InfoExtractor(object):\n             dump = base64.b64encode(webpage_bytes).decode('ascii')\n             self._downloader.to_screen(dump)\n         if self._downloader.params.get('write_pages', False):\n-            basen = '%s_%s' % (video_id, urlh.geturl())\n+            basen = '%s_%s' % (_video_id, urlh.geturl())\n             if len(basen) > 240:\n                 h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()\n                 basen = basen[:240 - len(h)] + h\n@@ -800,7 +804,7 @@ class InfoExtractor(object):\n     def _download_webpage(\n             self, url_or_request, video_id, note=None, errnote=None,\n             fatal=True, tries=1, timeout=5, encoding=None, data=None,\n-            headers={}, query={}, expected_status=None):\n+            headers=None, query=None, expected_status=None):\n         \"\"\"\n         Return the data of the page as a string.\n \n@@ -834,6 +838,8 @@ class InfoExtractor(object):\n             Note that this argument does not affect success status codes (2xx)\n             which are always accepted.\n         \"\"\"\n+        headers = headers or {}\n+        query = query or {}\n \n         success = False\n         try_count = 0\n"
}