{
  "patch": "diff --git a/youtube_dl/extractor/common.py b/youtube_dl/extractor/common.py\nindex 9b0016d07..5a849b022 100644\n--- a/youtube_dl/extractor/common.py\n+++ b/youtube_dl/extractor/common.py\n@@ -26,8 +26,8 @@ from ..compat import (\n     compat_integer_types,\n     compat_http_client,\n     compat_kwargs,\n-    compat_map as map,\n-    compat_open as open,\n+    compat_map,\n+    compat_open,\n     compat_os_name,\n     compat_str,\n     compat_urllib_error,\n@@ -36,7 +36,7 @@ from ..compat import (\n     compat_urllib_request,\n     compat_urlparse,\n     compat_xml_parse_error,\n-    compat_zip as zip,\n+    compat_zip,\n )\n from ..downloader.f4m import (\n     get_base_url,\n@@ -436,7 +436,9 @@ class InfoExtractor(object):\n         # match its superclass\n         if '_VALID_URL_RE' not in cls.__dict__:\n             # _VALID_URL can now be a list/tuple of patterns\n-            cls._VALID_URL_RE = tuple(map(re.compile, variadic(cls._VALID_URL)))\n+            if not hasattr(cls, '_VALID_URL'):\n+                return None\n+            cls._VALID_URL_RE = tuple(compat_map(re.compile, variadic(cls._VALID_URL)))\n         # 20% faster than next(filter(None, (p.match(url) for p in cls._VALID_URL_RE)), None) in 2.7\n         for p in cls._VALID_URL_RE:\n             p = p.match(url)\n@@ -569,6 +571,8 @@ class InfoExtractor(object):\n                 try:\n                     self.initialize()\n                     ie_result = self._real_extract(url)\n+                    if ie_result is None:\n+                        ie_result = {}\n                     if self._x_forwarded_for_ip:\n                         ie_result['__x_forwarded_for_ip'] = self._x_forwarded_for_ip\n                     return ie_result\n@@ -579,9 +583,9 @@ class InfoExtractor(object):\n         except ExtractorError:\n             raise\n         except compat_http_client.IncompleteRead as e:\n-            raise ExtractorError('A network error has occurred.', cause=e, expected=True)\n+            raise ExtractorError('A network error has occurred.', cause=e, expected=True) from e\n         except (KeyError, StopIteration) as e:\n-            raise ExtractorError('An extractor error has occurred.', cause=e)\n+            raise ExtractorError('An extractor error has occurred.', cause=e) from e\n \n     def __maybe_fake_ip_and_retry(self, countries):\n         if (not self._downloader.params.get('geo_bypass_country', None)\n@@ -612,11 +616,9 @@ class InfoExtractor(object):\n \n     def _real_initialize(self):\n         \"\"\"Real initialization process. Redefine in subclasses.\"\"\"\n-        pass\n \n     def _real_extract(self, url):\n         \"\"\"Real extraction process. Redefine in subclasses.\"\"\"\n-        pass\n \n     @classmethod\n     def ie_key(cls):\n@@ -641,12 +643,17 @@ class InfoExtractor(object):\n         else:\n             assert False\n \n-    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers={}, query={}, expected_status=None):\n+    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers=None, query=None, expected_status=None):\n         \"\"\"\n         Return the response handle.\n \n         See _download_webpage docstring for arguments specification.\n         \"\"\"\n+        if headers is None:\n+            headers = {}\n+        if query is None:\n+            query = {}\n+            \n         if note is None:\n             self.report_download_webpage(video_id)\n         elif note is not False:\n@@ -699,12 +706,17 @@ class InfoExtractor(object):\n                 self._downloader.report_warning(errmsg)\n                 return False\n \n-    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers={}, query={}, expected_status=None):\n+    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers=None, query=None, expected_status=None):\n         \"\"\"\n         Return a tuple (page content as string, URL handle).\n \n         See _download_webpage docstring for arguments specification.\n         \"\"\"\n+        if headers is None:\n+            headers = {}\n+        if query is None:\n+            query = {}\n+            \n         # Strip hashes from the URL (#1038)\n         if isinstance(url_or_request, (compat_str, str)):\n             url_or_request = url_or_request.partition('#')[0]\n@@ -761,7 +773,7 @@ class InfoExtractor(object):\n                 'Visit http://blocklist.rkn.gov.ru/ for a block reason.',\n                 expected=True)\n \n-    def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None):\n+    def _webpage_read_content(self, urlh, _url_or_request, _video_id, _note=None, _errnote=None, _fatal=True, prefix=None, encoding=None):\n         content_type = urlh.headers.get('Content-Type', '')\n         webpage_bytes = urlh.read()\n         if prefix is not None:\n@@ -773,7 +785,7 @@ class InfoExtractor(object):\n             dump = base64.b64encode(webpage_bytes).decode('ascii')\n             self._downloader.to_screen(dump)\n         if self._downloader.params.get('write_pages', False):\n-            basen = '%s_%s' % (video_id, urlh.geturl())\n+            basen = '%s_%s' % (_video_id, urlh.geturl())\n             if len(basen) > 240:\n                 h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()\n                 basen = basen[:240 - len(h)] + h\n@@ -786,7 +798,7 @@ class InfoExtractor(object):\n                 absfilepath = os.path.abspath(filename)\n                 if len(absfilepath) > 259:\n                     filename = '\\\\\\\\?\\\\' + absfilepath\n-            with open(filename, 'wb') as outf:\n+            with compat_open(filename, 'wb') as outf:\n                 outf.write(webpage_bytes)\n \n         try:\n@@ -801,7 +813,7 @@ class InfoExtractor(object):\n     def _download_webpage(\n             self, url_or_request, video_id, note=None, errnote=None,\n             fatal=True, tries=1, timeout=5, encoding=None, data=None,\n-            headers={}, query={}, expected_status=None):\n+            headers=None, query=None, expected_status=None):\n         \"\"\"\n         Return the data of the page as a string.\n \n@@ -835,6 +847,10 @@ class InfoExtractor(object):\n             Note that this argument does not affect success status codes (2xx)\n             which are always accepted.\n         \"\"\"\n+        if headers is None:\n+            headers = {}\n+        if query is None:\n+            query = {}\n \n         success = False\n         try_count = 0\n"
}