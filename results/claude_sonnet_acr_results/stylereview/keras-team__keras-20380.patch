{
  "patch": "diff --git a/keras/src/backend/numpy/trainer.py b/keras/src/backend/numpy/trainer.py\nindex 69a623f96..c2f56607f 100644\n--- a/keras/src/backend/numpy/trainer.py\n+++ b/keras/src/backend/numpy/trainer.py\n@@ -12,7 +12,7 @@ from keras.src.trainers.epoch_iterator import EpochIterator\n from keras.src.utils import traceback_utils\n \n \n-class NumpyTrainer(base_trainer.Trainer):\n+class NumpyTrainer(base_trainer.Trainer, Layer):\n     def __init__(self):\n         super().__init__()\n         self.test_function = None\n@@ -91,7 +91,7 @@ class NumpyTrainer(base_trainer.Trainer):\n \n         self.predict_function = predict_step\n \n-    def _symbolic_build(self, data_batch):\n+    def _symbolic_build(self, iterator=None, data_batch=None):\n         model_unbuilt = not all(layer.built for layer in self._flatten_layers())\n         compile_metrics_unbuilt = (\n             self._compile_metrics is not None\n@@ -117,7 +117,7 @@ class NumpyTrainer(base_trainer.Trainer):\n             # Build all model state with `backend.compute_output_spec`.\n             try:\n                 y_pred = backend.compute_output_spec(self, x)\n-            except:\n+            except Exception as exc:\n                 raise RuntimeError(\n                     \"Unable to automatically build the model. \"\n                     \"Please build it yourself before calling \"\n@@ -126,7 +126,7 @@ class NumpyTrainer(base_trainer.Trainer):\n                     \"been created and its `self.built` attribute \"\n                     \"is True. Usually, calling the model on a batch \"\n                     \"of data is the right way to build it.\"\n-                )\n+                ) from exc\n             if compile_metrics_unbuilt:\n                 # Build all metric state with `backend.compute_output_spec`.\n                 backend.compute_output_spec(\n@@ -320,7 +320,7 @@ class NumpyTrainer(base_trainer.Trainer):\n         self.make_test_function()\n \n         logs = self.test_function([data])\n-        logs = tree.map_structure(lambda x: np.array(x), logs)\n+        logs = tree.map_structure(np.array, logs)\n         if return_dict:\n             return logs\n         return self._flatten_metrics_in_order(logs)\ndiff --git a/keras/src/callbacks/callback_list.py b/keras/src/callbacks/callback_list.py\nindex b74d1ad4d..bad8437a3 100644\n--- a/keras/src/callbacks/callback_list.py\n+++ b/keras/src/callbacks/callback_list.py\n@@ -36,6 +36,7 @@ class CallbackList(Callback):\n             **params: If provided, parameters will be passed to each `Callback`\n                 via `Callback.set_params`.\n         \"\"\"\n+        super().__init__()\n         self.callbacks = tree.flatten(callbacks) if callbacks else []\n         self._executor = None\n         self._futures = []\ndiff --git a/keras/src/trainers/trainer.py b/keras/src/trainers/trainer.py\nindex 3668a988a..d5b5efb5c 100644\n--- a/keras/src/trainers/trainer.py\n+++ b/keras/src/trainers/trainer.py\n@@ -18,6 +18,7 @@ from keras.src.utils import tracking\n \n class Trainer:\n     def __init__(self):\n+        super().__init__()\n         self._lock = False\n         self._run_eagerly = False\n         self._jit_compile = None\n@@ -1033,10 +1034,10 @@ class Trainer:\n     def _assert_compile_called(self, method_name=None):\n         if not self.compiled:\n             msg = \"You must call `compile()` before \"\n-            if metrics_module:\n-                msg += \"using the model.\"\n-            else:\n+            if method_name:\n                 msg += f\"calling `{method_name}()`.\"\n+            else:\n+                msg += \"using the model.\"\n             raise ValueError(msg)\n \n     def _symbolic_build(self, iterator=None, data_batch=None):\n@@ -1086,7 +1087,7 @@ class Trainer:\n                     \"of data is the right way to build it.\\n\"\n                     \"Exception encountered:\\n\"\n                     f\"'{e}'\"\n-                )\n+                ) from e\n             if compile_metrics_unbuilt:\n                 # Build all metric state with `backend.compute_output_spec`.\n                 backend.compute_output_spec(\n"
}