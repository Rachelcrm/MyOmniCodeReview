{
  "patch": "diff --git a/scrapy/downloadermiddlewares/retry.py b/scrapy/downloadermiddlewares/retry.py\nindex 081642a4b..94947fc67 100644\n--- a/scrapy/downloadermiddlewares/retry.py\n+++ b/scrapy/downloadermiddlewares/retry.py\n@@ -146,6 +146,30 @@ class RetryMiddleware:\n             int(x) for x in settings.getlist(\"RETRY_HTTP_CODES\")\n         )\n         self.priority_adjust = settings.getint(\"RETRY_PRIORITY_ADJUST\")\n+        \n+        # Configure retry exceptions\n+        retry_exceptions_setting = settings.getlist(\"RETRY_EXCEPTIONS\")\n+        if retry_exceptions_setting:\n+            # Map exception class names to actual classes\n+            exception_map = {\n+                'defer.TimeoutError': defer.TimeoutError,\n+                'TimeoutError': TimeoutError,\n+                'DNSLookupError': DNSLookupError,\n+                'ConnectionRefusedError': ConnectionRefusedError,\n+                'ConnectionDone': ConnectionDone,\n+                'ConnectError': ConnectError,\n+                'ConnectionLost': ConnectionLost,\n+                'TCPTimedOutError': TCPTimedOutError,\n+                'ResponseFailed': ResponseFailed,\n+                'IOError': IOError,\n+                'TunnelError': TunnelError,\n+            }\n+            self.exceptions_to_retry = tuple(\n+                exception_map[exc_name] for exc_name in retry_exceptions_setting\n+                if exc_name in exception_map\n+            )\n+        else:\n+            self.exceptions_to_retry = self.EXCEPTIONS_TO_RETRY\n \n     @classmethod\n     def from_crawler(cls, crawler):\n@@ -160,7 +184,7 @@ class RetryMiddleware:\n         return response\n \n     def process_exception(self, request, exception, spider):\n-        if isinstance(exception, self.EXCEPTIONS_TO_RETRY) and not request.meta.get(\n+        if isinstance(exception, self.exceptions_to_retry) and not request.meta.get(\n             \"dont_retry\", False\n         ):\n             return self._retry(request, exception, spider)\n"
}