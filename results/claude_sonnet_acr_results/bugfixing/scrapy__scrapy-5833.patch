{
  "patch": "diff --git a/scrapy/extensions/feedexport.py b/scrapy/extensions/feedexport.py\nindex cd26b5778..7b07d12f7 100644\n--- a/scrapy/extensions/feedexport.py\n+++ b/scrapy/extensions/feedexport.py\n@@ -204,12 +204,79 @@ class S3FeedStorage(BlockingFeedStorage):\n         )\n \n     def _store_in_thread(self, file):\n-        file.seek(0)\n+        file.seek(0, 2)  # Seek to end to get file size\n+        file_size = file.tell()\n+        file.seek(0)  # Reset to beginning\n+        \n+        # AWS S3 put_object limit is 5GB\n+        max_single_upload_size = 5 * 1024 * 1024 * 1024  # 5GB in bytes\n+        \n         kwargs = {\"ACL\": self.acl} if self.acl else {}\n-        self.s3_client.put_object(\n-            Bucket=self.bucketname, Key=self.keyname, Body=file, **kwargs\n-        )\n+        \n+        if file_size < max_single_upload_size:\n+            # Use regular put_object for files under 5GB\n+            self.s3_client.put_object(\n+                Bucket=self.bucketname, Key=self.keyname, Body=file, **kwargs\n+            )\n+        else:\n+            # Use multipart upload for files 5GB or larger\n+            self._multipart_upload(file, **kwargs)\n+        \n         file.close()\n+    \n+    def _multipart_upload(self, file, **kwargs):\n+        # Create multipart upload\n+        create_kwargs = {\"Bucket\": self.bucketname, \"Key\": self.keyname}\n+        create_kwargs.update(kwargs)\n+        \n+        response = self.s3_client.create_multipart_upload(**create_kwargs)\n+        upload_id = response[\"UploadId\"]\n+        \n+        try:\n+            parts = []\n+            part_number = 1\n+            chunk_size = 5 * 1024 * 1024  # 5MB chunks\n+            \n+            while True:\n+                chunk = file.read(chunk_size)\n+                if not chunk:\n+                    break\n+                \n+                # Upload part\n+                part_response = self.s3_client.upload_part(\n+                    Bucket=self.bucketname,\n+                    Key=self.keyname,\n+                    PartNumber=part_number,\n+                    UploadId=upload_id,\n+                    Body=chunk\n+                )\n+                \n+                parts.append({\n+                    \"ETag\": part_response[\"ETag\"],\n+                    \"PartNumber\": part_number\n+                })\n+                \n+                part_number += 1\n+            \n+            # Complete multipart upload\n+            self.s3_client.complete_multipart_upload(\n+                Bucket=self.bucketname,\n+                Key=self.keyname,\n+                UploadId=upload_id,\n+                MultipartUpload={\"Parts\": parts}\n+            )\n+            \n+        except Exception:\n+            # Abort multipart upload on any error\n+            try:\n+                self.s3_client.abort_multipart_upload(\n+                    Bucket=self.bucketname,\n+                    Key=self.keyname,\n+                    UploadId=upload_id\n+                )\n+            except Exception:\n+                pass  # Ignore errors when aborting\n+            raise\n \n \n class GCSFeedStorage(BlockingFeedStorage):\n"
}